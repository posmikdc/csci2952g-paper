{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c745a391",
   "metadata": {},
   "source": [
    "# Graph Neural Network with Node Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed29abd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f1ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the main path\n",
    "main_path = '/Users/posmikdc/Documents/brown/classes/year2/fall25/csci2952g-dlgenomics/csci2952g-paper'\n",
    "data_path = os.path.join(main_path, 'data/gao_shs27k_data')\n",
    "\n",
    "# Define data and file objects\n",
    "data = {}\n",
    "files = [\n",
    "    'protein.actions.SHS27k.STRING.pro2.txt',\n",
    "    'protein.SHS27k.sequences.dictionary.pro3.tsv',\n",
    "    'edge_list_12.npy',\n",
    "    'x_list.pt',\n",
    "    'vec5_CTC.txt'\n",
    "]\n",
    "\n",
    "# Read in files based on extension\n",
    "for file in files:\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    key = os.path.splitext(file)[0]\n",
    "    \n",
    "    if file.endswith('.npy'):\n",
    "        data[key] = np.load(file_path, allow_pickle=True)\n",
    "    elif file.endswith('.pt'):\n",
    "        data[key] = torch.load(file_path, weights_only=False)\n",
    "    elif file.endswith('.tsv'):\n",
    "        data[key] = pd.read_csv(file_path, sep='\\t')\n",
    "    else:\n",
    "        data[key] = pd.read_csv(file_path, sep=r'\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d9e95",
   "metadata": {},
   "source": [
    "## Baseline GNN: GCN Approach with Protein Degree as Node Features\n",
    "\n",
    "This baseline GNN uses protein degree as node features (simple but informative). We implement link prediction to predict protein interactions. We create negative samples (non-interacting protein pairs) for training\n",
    "\n",
    "This GNN approach uses GCN layers to aggregate neighborhood information. Evaluates with AUC, AP, and F1 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2587c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Graph Data\n",
    "def create_graph_data(ppi_df, min_score=0):\n",
    "    \"\"\"\n",
    "    Create PyTorch Geometric graph data from PPI dataframe.\n",
    "    Uses protein degree as simple node features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ppi_df : pd.DataFrame\n",
    "        PPI dataframe\n",
    "    min_score : int\n",
    "        Minimum score threshold\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    data : torch_geometric.data.Data\n",
    "        Graph data object\n",
    "    protein_to_idx : dict\n",
    "        Mapping from protein ID to node index\n",
    "    \"\"\"\n",
    "    # Filter by score\n",
    "    df = ppi_df[ppi_df['score'] >= min_score].copy()\n",
    "    \n",
    "    # Get unique proteins\n",
    "    proteins = pd.concat([df['item_id_a'], df['item_id_b']]).unique()\n",
    "    protein_to_idx = {prot: idx for idx, prot in enumerate(proteins)}\n",
    "    idx_to_protein = {idx: prot for prot, idx in protein_to_idx.items()}\n",
    "    \n",
    "    print(f\"Number of proteins (nodes): {len(proteins)}\")\n",
    "    print(f\"Number of interactions (edges): {len(df)}\")\n",
    "    \n",
    "    # Create edge index\n",
    "    edge_index = []\n",
    "    edge_labels = []\n",
    "    edge_scores = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        src = protein_to_idx[row['item_id_a']]\n",
    "        dst = protein_to_idx[row['item_id_b']]\n",
    "        edge_index.append([src, dst])\n",
    "        edge_index.append([dst, src])  # Add reverse edge for undirected graph\n",
    "        \n",
    "        # Binary label: 1 if interaction exists\n",
    "        edge_labels.extend([1, 1])\n",
    "        edge_scores.extend([row['score'], row['score']])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_labels = torch.tensor(edge_labels, dtype=torch.float)\n",
    "    edge_scores = torch.tensor(edge_scores, dtype=torch.float)\n",
    "    \n",
    "    # Create node features: [degree, normalized_degree, clustering_coefficient]\n",
    "    import networkx as nx\n",
    "    G = nx.Graph()\n",
    "    for _, row in df.iterrows():\n",
    "        G.add_edge(row['item_id_a'], row['item_id_b'])\n",
    "    \n",
    "    node_features = []\n",
    "    for idx in range(len(proteins)):\n",
    "        prot = idx_to_protein[idx]\n",
    "        degree = G.degree(prot) if prot in G else 0\n",
    "        node_features.append([degree])\n",
    "    \n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    # Normalize features\n",
    "    node_features = (node_features - node_features.mean(dim=0)) / (node_features.std(dim=0) + 1e-8)\n",
    "    \n",
    "    # Create negative samples (non-edges)\n",
    "    num_nodes = len(proteins)\n",
    "    num_neg_samples = len(edge_labels) // 2  # Same number as positive edges\n",
    "    \n",
    "    neg_edge_index = []\n",
    "    existing_edges = set(map(tuple, edge_index.t().numpy()))\n",
    "    \n",
    "    while len(neg_edge_index) < num_neg_samples:\n",
    "        src = np.random.randint(0, num_nodes)\n",
    "        dst = np.random.randint(0, num_nodes)\n",
    "        if src != dst and (src, dst) not in existing_edges and (dst, src) not in existing_edges:\n",
    "            neg_edge_index.append([src, dst])\n",
    "            neg_edge_index.append([dst, src])\n",
    "    \n",
    "    neg_edge_index = torch.tensor(neg_edge_index, dtype=torch.long).t().contiguous()\n",
    "    neg_edge_labels = torch.zeros(len(neg_edge_index[0]), dtype=torch.float)\n",
    "    \n",
    "    # Combine positive and negative edges\n",
    "    all_edge_index = torch.cat([edge_index, neg_edge_index], dim=1)\n",
    "    all_edge_labels = torch.cat([edge_labels, neg_edge_labels])\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(x=node_features, edge_index=edge_index)\n",
    "    data.edge_label_index = all_edge_index\n",
    "    data.edge_label = all_edge_labels\n",
    "    data.num_nodes = len(proteins)\n",
    "    \n",
    "    print(f\"Node feature shape: {node_features.shape}\")\n",
    "    print(f\"Positive edges: {len(edge_labels) // 2}\")\n",
    "    print(f\"Negative edges: {len(neg_edge_labels) // 2}\")\n",
    "    \n",
    "    return data, protein_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cca4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN (for Link Prediction)\n",
    "class GNN_LinkPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple GNN for link prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        \n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        # Link prediction head\n",
    "        self.lin = nn.Linear(hidden_channels * 2, 1)\n",
    "        \n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"Encode nodes to embeddings.\"\"\"\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        \"\"\"Decode edge predictions from node embeddings.\"\"\"\n",
    "        # Concatenate source and target node embeddings\n",
    "        src = z[edge_label_index[0]]\n",
    "        dst = z[edge_label_index[1]]\n",
    "        edge_emb = torch.cat([src, dst], dim=-1)\n",
    "        return self.lin(edge_emb).squeeze()\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_label_index):\n",
    "        z = self.encode(x, edge_index)\n",
    "        return self.decode(z, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734ca551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_gnn(data, model, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    out = model(data.x, data.edge_index, data.edge_label_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(out, data.edge_label)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8391032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_gnn(data, model, device):\n",
    "    \"\"\"Evaluate model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index, data.edge_label_index)\n",
    "        pred = torch.sigmoid(out).cpu().numpy()\n",
    "        labels = data.edge_label.cpu().numpy()\n",
    "        \n",
    "        auc = roc_auc_score(labels, pred)\n",
    "        ap = average_precision_score(labels, pred)\n",
    "        pred_binary = (pred > 0.5).astype(int)\n",
    "        f1 = f1_score(labels, pred_binary)\n",
    "    \n",
    "    return auc, ap, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0910b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proteins (nodes): 784\n",
      "Number of interactions (edges): 4810\n",
      "Node feature shape: torch.Size([784, 1])\n",
      "Positive edges: 4810\n",
      "Negative edges: 2405\n",
      "\n",
      "Training GNN...\n",
      "Epoch 010, Loss: 0.5358\n",
      "  Train - AUC: 0.7918, AP: 0.8937, F1: 0.8023\n",
      "  Val   - AUC: 0.8129, AP: 0.9030, F1: 0.8130\n",
      "Epoch 020, Loss: 0.5135\n",
      "  Train - AUC: 0.8135, AP: 0.9002, F1: 0.8151\n",
      "  Val   - AUC: 0.8358, AP: 0.9105, F1: 0.8195\n",
      "Epoch 030, Loss: 0.4900\n",
      "  Train - AUC: 0.8289, AP: 0.9053, F1: 0.8385\n",
      "  Val   - AUC: 0.8503, AP: 0.9159, F1: 0.8502\n",
      "Epoch 040, Loss: 0.4615\n",
      "  Train - AUC: 0.8589, AP: 0.9142, F1: 0.8603\n",
      "  Val   - AUC: 0.8793, AP: 0.9252, F1: 0.8711\n",
      "Epoch 050, Loss: 0.4498\n",
      "  Train - AUC: 0.8692, AP: 0.9160, F1: 0.8798\n",
      "  Val   - AUC: 0.8896, AP: 0.9278, F1: 0.8845\n",
      "Epoch 060, Loss: 0.4444\n",
      "  Train - AUC: 0.8715, AP: 0.9154, F1: 0.8760\n",
      "  Val   - AUC: 0.8920, AP: 0.9277, F1: 0.8872\n",
      "Epoch 070, Loss: 0.4321\n",
      "  Train - AUC: 0.8719, AP: 0.9157, F1: 0.8827\n",
      "  Val   - AUC: 0.8921, AP: 0.9278, F1: 0.8916\n",
      "Epoch 080, Loss: 0.4356\n",
      "  Train - AUC: 0.8722, AP: 0.9150, F1: 0.8791\n",
      "  Val   - AUC: 0.8922, AP: 0.9273, F1: 0.8893\n",
      "Epoch 090, Loss: 0.4388\n",
      "  Train - AUC: 0.8727, AP: 0.9156, F1: 0.8854\n",
      "  Val   - AUC: 0.8922, AP: 0.9273, F1: 0.8941\n",
      "Epoch 100, Loss: 0.4389\n",
      "  Train - AUC: 0.8730, AP: 0.9158, F1: 0.8796\n",
      "  Val   - AUC: 0.8921, AP: 0.9274, F1: 0.8853\n",
      "\n",
      "Test Results - AUC: 0.8763, AP: 0.9208, F1: 0.8789\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "ppi_df = data['protein.actions.SHS27k.STRING.pro2']\n",
    "\n",
    "# Create graph data\n",
    "graph_data, protein_to_idx = create_graph_data(ppi_df, min_score=400)\n",
    "\n",
    "# Split edges into train/val/test\n",
    "num_edges = len(graph_data.edge_label)\n",
    "indices = torch.randperm(num_edges)\n",
    "train_size = int(0.7 * num_edges)\n",
    "val_size = int(0.15 * num_edges)\n",
    "\n",
    "train_idx = indices[:train_size]\n",
    "val_idx = indices[train_size:train_size + val_size]\n",
    "test_idx = indices[train_size + val_size:]\n",
    "\n",
    "train_data = Data(\n",
    "    x=graph_data.x,\n",
    "    edge_index=graph_data.edge_index,\n",
    "    edge_label_index=graph_data.edge_label_index[:, train_idx],\n",
    "    edge_label=graph_data.edge_label[train_idx]\n",
    ")\n",
    "\n",
    "val_data = Data(\n",
    "    x=graph_data.x,\n",
    "    edge_index=graph_data.edge_index,\n",
    "    edge_label_index=graph_data.edge_label_index[:, val_idx],\n",
    "    edge_label=graph_data.edge_label[val_idx]\n",
    ")\n",
    "\n",
    "test_data = Data(\n",
    "    x=graph_data.x,\n",
    "    edge_index=graph_data.edge_index,\n",
    "    edge_label_index=graph_data.edge_label_index[:, test_idx],\n",
    "    edge_label=graph_data.edge_label[test_idx]\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GNN_LinkPredictor(in_channels=graph_data.x.shape[1], hidden_channels=64, num_layers=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Move data to device\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nTraining GNN...\")\n",
    "for epoch in range(1, 101):\n",
    "    loss = train_gnn(train_data, model, optimizer, device)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        train_auc, train_ap, train_f1 = evaluate_gnn(train_data, model, device)\n",
    "        val_auc, val_ap, val_f1 = evaluate_gnn(val_data, model, device)\n",
    "        \n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')\n",
    "        print(f'  Train - AUC: {train_auc:.4f}, AP: {train_ap:.4f}, F1: {train_f1:.4f}')\n",
    "        print(f'  Val   - AUC: {val_auc:.4f}, AP: {val_ap:.4f}, F1: {val_f1:.4f}')\n",
    "\n",
    "# Final test evaluation\n",
    "test_auc, test_ap, test_f1 = evaluate_gnn(test_data, model, device)\n",
    "print(f'\\nTest Results - AUC: {test_auc:.4f}, AP: {test_ap:.4f}, F1: {test_f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
