protein num: 1553
protein average length: 528.5151320025757
protein max & min length: 2517, 51
acid vector dimension: 13
Connected domain num: 20
Final check on x_num_index sum: 818994
train gnn, train_num: 5328, valid_num: 1332
cuda:0
epoch: 0, step: 0, Train: label_loss: 1.360796332359314, precision: 0.17142857142808163, recall: 0.42857142856836733, f1: 0.24489795914185755
epoch: 0, step: 1, Train: label_loss: 0.8021994233131409, precision: 0.41176470587993086, recall: 0.41176470587993086, f1: 0.41176470582993085
epoch: 0, step: 2, Train: label_loss: 0.8912324905395508, precision: 0.2777777777762346, recall: 0.2777777777762346, f1: 0.2777777777262346
epoch: 0, step: 3, Train: label_loss: 1.1724430322647095, precision: 0.38888888888672846, recall: 0.38888888888672846, f1: 0.38888888883672845
epoch: 0, step: 4, Train: label_loss: 1.2991178035736084, precision: 0.14999999999925, recall: 0.2727272727247934, f1: 0.19354838704973987
epoch: 0, step: 5, Train: label_loss: 1.3074859380722046, precision: 0.39130434782438567, recall: 0.5294117647027682, f1: 0.449999999948875
epoch: 0, step: 6, Train: label_loss: 0.8253927826881409, precision: 0.4374999999972657, recall: 0.41176470587993086, f1: 0.42424242418989905
epoch: 0, step: 7, Train: label_loss: 1.491636037826538, precision: 0.399999999996, recall: 0.24999999999843753, f1: 0.3076923076426036
epoch: 0, step: 8, Train: label_loss: 0.6556098461151123, precision: 0.42857142856836733, recall: 0.3749999999976563, f1: 0.3999999999475556
epoch: 0, step: 9, Train: label_loss: 1.0922235250473022, precision: 0.5714285714258504, recall: 0.5217391304325142, f1: 0.5454545454021694
epoch: 0, step: 10, Train: label_loss: 0.9705386161804199, precision: 0.3333333333314815, recall: 0.3749999999976563, f1: 0.35294117641868517
epoch: 0, step: 11, Train: label_loss: 1.8621678352355957, precision: 0.41666666666319446, recall: 0.23809523809410432, f1: 0.30303030298218553
epoch: 0, step: 12, Train: label_loss: 0.7211045026779175, precision: 0.46666666666355555, recall: 0.3333333333317461, f1: 0.3888888888381174
epoch: 0, step: 13, Train: label_loss: 0.9369364976882935, precision: 0.31818181818037194, recall: 0.46666666666355555, f1: 0.37837837832812277
epoch: 0, step: 14, Train: label_loss: 0.8237994313240051, precision: 0.23076923076745562, recall: 0.21428571428418366, f1: 0.22222222217064472
epoch: 0, step: 15, Train: label_loss: 1.4979010820388794, precision: 0.34999999999825004, recall: 0.5384615384573964, f1: 0.42424242419210284
epoch: 0, step: 16, Train: label_loss: 1.0082889795303345, precision: 0.49999999999750006, recall: 0.588235294114187, f1: 0.5405405404879474
epoch: 0, step: 17, Train: label_loss: 1.4059901237487793, precision: 0.6666666666634922, recall: 0.4999999999982143, f1: 0.5714285713772596
epoch: 0, step: 18, Train: label_loss: 1.4466240406036377, precision: 0.7857142857086735, recall: 0.40740740740589854, f1: 0.5365853658060679
epoch: 0, step: 19, Train: label_loss: 0.7034728527069092, precision: 0.74999999999375, recall: 0.3461538461525148, f1: 0.4736842104806095
epoch: 0, step: 20, Train: label_loss: 0.6224446296691895, precision: 0.47619047618820864, recall: 0.588235294114187, f1: 0.5263157894214683
epoch: 0, step: 21, Train: label_loss: 0.7686132192611694, precision: 0.199999999999, recall: 0.3076923076899408, f1: 0.24242424237502297
epoch: 0, step: 22, Train: label_loss: 0.9337157011032104, precision: 0.46153846153668643, recall: 0.7058823529370243, f1: 0.5581395348333155
epoch: 0, step: 23, Train: label_loss: 0.6033914685249329, precision: 0.4705882352913495, recall: 0.49999999999687506, f1: 0.4848484847955923
epoch: 0, step: 24, Train: label_loss: 0.801487147808075, precision: 0.5714285714244898, recall: 0.42105263157673134, f1: 0.48484848479669423
epoch: 0, step: 25, Train: label_loss: 0.6226018667221069, precision: 0.7368421052592798, recall: 0.5833333333309029, f1: 0.6511627906453218
epoch: 0, step: 26, Train: label_loss: 0.5947062969207764, precision: 0.41176470587993086, recall: 0.5384615384573964, f1: 0.4666666666144445
epoch: 0, step: 27, Train: label_loss: 0.7008317112922668, precision: 0.5714285714244898, recall: 0.38095238095056694, f1: 0.45714285709224495
epoch: 0, step: 28, Train: label_loss: 0.8535271286964417, precision: 0.44999999999775003, recall: 0.5294117647027682, f1: 0.48648648643418557
epoch: 0, step: 29, Train: label_loss: 0.6494766473770142, precision: 0.40740740740589854, recall: 0.6874999999957032, f1: 0.5116279069276365
epoch: 0, step: 30, Train: label_loss: 0.7164808511734009, precision: 0.4374999999972657, recall: 0.34999999999825004, f1: 0.3888888888373458
epoch: 0, step: 31, Train: label_loss: 0.621032178401947, precision: 0.2727272727247934, recall: 0.23076923076745562, f1: 0.24999999994826386
epoch: 0, step: 32, Train: label_loss: 0.8633339405059814, precision: 0.399999999996, recall: 0.15999999999936002, f1: 0.22857142852930615
epoch: 0, step: 33, Train: label_loss: 0.7816213965415955, precision: 0.5454545454495868, recall: 0.2608695652162571, f1: 0.35294117642474054
epoch: 0, step: 34, Train: label_loss: 0.6710148453712463, precision: 0.3333333333296296, recall: 0.21428571428418366, f1: 0.2608695651674858
epoch: 0, step: 35, Train: label_loss: 0.6559387445449829, precision: 0.6666666666622222, recall: 0.3999999999984, f1: 0.499999999950625
epoch: 0, step: 36, Train: label_loss: 0.6344761252403259, precision: 0.16666666666527777, recall: 0.14285714285612244, f1: 0.15384615379526623
epoch: 0, step: 37, Train: label_loss: 0.6301114559173584, precision: 0.631578947365097, recall: 0.46153846153668643, f1: 0.5333333332821729
epoch: 0, step: 38, Train: label_loss: 0.652003288269043, precision: 0.44444444444197534, recall: 0.4705882352913495, f1: 0.45714285709028574
epoch: 0, step: 39, Train: label_loss: 0.6097186207771301, precision: 0.38461538461242606, recall: 0.41666666666319446, f1: 0.39999999994688007
epoch: 0, step: 40, Train: label_loss: 0.529106080532074, precision: 0.2857142857122449, recall: 0.399999999996, f1: 0.3333333332819444
epoch: 0, step: 41, Train: label_loss: 0.4933992922306061, precision: 0.5384615384573964, recall: 0.5384615384573964, f1: 0.5384615384073964
epoch: 0, step: 42, Train: label_loss: 0.6727195978164673, precision: 0.38461538461242606, recall: 0.2777777777762346, f1: 0.3225806451105099
epoch: 0, step: 43, Train: label_loss: 0.7478455305099487, precision: 0.3157894736825485, recall: 0.3999999999973333, f1: 0.35294117641920414
epoch: 0, step: 44, Train: label_loss: 0.5901609659194946, precision: 0.3999999999973333, recall: 0.3999999999973333, f1: 0.3999999999473333
epoch: 0, step: 45, Train: label_loss: 0.8225009441375732, precision: 0.399999999996, recall: 0.21052631578836567, f1: 0.27586206891843046
epoch: 0, step: 46, Train: label_loss: 0.7277466058731079, precision: 0.49999999999375, recall: 0.18181818181735537, f1: 0.26666666662577776
epoch: 0, step: 47, Train: label_loss: 0.5900184512138367, precision: 0.2727272727247934, recall: 0.21428571428418366, f1: 0.2399999999488
epoch: 0, step: 48, Train: label_loss: 0.6031039357185364, precision: 0.35714285714030614, recall: 0.2777777777762346, f1: 0.3124999999488281
epoch: 0, step: 49, Train: label_loss: 0.5108251571655273, precision: 0.46666666666355555, recall: 0.5384615384573964, f1: 0.4999999999466836
epoch: 0, step: 50, Train: label_loss: 0.6161516904830933, precision: 0.42857142856836733, recall: 0.3333333333314815, f1: 0.37499999994843747
epoch: 0, step: 51, Train: label_loss: 0.5964910387992859, precision: 0.35294117646851214, recall: 0.5454545454495868, f1: 0.4285714285206634
epoch: 0, step: 52, Train: label_loss: 1.1528981924057007, precision: 0.4999999999964286, recall: 0.31818181818037194, f1: 0.38888888883919753
epoch: 0, step: 53, Train: label_loss: 0.5903465747833252, precision: 0.6666666666592592, recall: 0.2999999999985, f1: 0.41379310340261594
epoch: 0, step: 54, Train: label_loss: 0.6890355944633484, precision: 0.4999999999964286, recall: 0.34999999999825004, f1: 0.41176470583148794
epoch: 0, step: 55, Train: label_loss: 0.5609211325645447, precision: 0.45454545454132234, recall: 0.35714285714030614, f1: 0.39999999994752
epoch: 0, step: 56, Train: label_loss: 0.602545440196991, precision: 0.49999999999166667, recall: 0.14999999999925, f1: 0.23076923073195266
epoch: 0, step: 57, Train: label_loss: 0.6351293325424194, precision: 0.11111111110987654, recall: 0.07142857142806122, f1: 0.08695652169073723
epoch: 0, step: 58, Train: label_loss: 0.6388629078865051, precision: 0.199999999998, recall: 0.10526315789418283, f1: 0.13793103443662308
epoch: 0, step: 59, Train: label_loss: 0.6498197913169861, precision: 0.38461538461242606, recall: 0.2777777777762346, f1: 0.3225806451105099
epoch: 0, step: 60, Train: label_loss: 0.6743906736373901, precision: 0.5454545454495868, recall: 0.2608695652162571, f1: 0.35294117642474054
epoch: 0, step: 61, Train: label_loss: 0.7419946193695068, precision: 0.19999999999866666, recall: 0.17647058823425607, f1: 0.18749999994902344
epoch: 0, step: 62, Train: label_loss: 0.6541191935539246, precision: 0.2857142857102041, recall: 0.0999999999995, f1: 0.14814814810864196
epoch: 0, step: 63, Train: label_loss: 0.5834072828292847, precision: 0.5294117647027682, recall: 0.4999999999972223, f1: 0.5142857142328163
epoch: 0, step: 64, Train: label_loss: 0.6163565516471863, precision: 0.3749999999976563, recall: 0.3333333333314815, f1: 0.35294117641868517
epoch: 0, step: 65, Train: label_loss: 0.5860927700996399, precision: 0.46153846153491124, recall: 0.2999999999985, f1: 0.36363636358640955
epoch: 0, step: 66, Train: label_loss: 0.6635649800300598, precision: 0.3333333333314815, recall: 0.3157894736825485, f1: 0.32432432427260777
epoch: 0, step: 67, Train: label_loss: 0.5064296722412109, precision: 0.499999999995, recall: 0.35714285714030614, f1: 0.41666666661458335
epoch: 0, step: 68, Train: label_loss: 0.5551493167877197, precision: 0.49999999999687506, recall: 0.5333333333297777, f1: 0.5161290322047868
epoch: 0, step: 69, Train: label_loss: 0.6272525191307068, precision: 0.5263157894709142, recall: 0.5555555555524692, f1: 0.5405405404876553
epoch: 0, step: 70, Train: label_loss: 0.6183271408081055, precision: 0.49999999999583333, recall: 0.3333333333314815, f1: 0.39999999994933333
epoch: 0, step: 71, Train: label_loss: 0.7899953722953796, precision: 0.5714285714244898, recall: 0.399999999998, f1: 0.4705882352429066
epoch: 0, step: 72, Train: label_loss: 0.6153525710105896, precision: 0.5454545454495868, recall: 0.3157894736825485, f1: 0.399999999950889
epoch: 0, step: 73, Train: label_loss: 0.7349764108657837, precision: 0.5714285714244898, recall: 0.38095238095056694, f1: 0.45714285709224495
epoch: 0, step: 74, Train: label_loss: 0.6989606618881226, precision: 0.3076923076899408, recall: 0.22222222222098767, f1: 0.25806451607866804
epoch: 0, step: 75, Train: label_loss: 0.6140931248664856, precision: 0.5624999999964845, recall: 0.5294117647027682, f1: 0.5454545454012856
epoch: 0, step: 76, Train: label_loss: 0.6468619108200073, precision: 0.3999999999973333, recall: 0.46153846153491124, f1: 0.42857142851862245
epoch: 0, step: 77, Train: label_loss: 0.5562688112258911, precision: 0.49999999999583333, recall: 0.3157894736825485, f1: 0.38709677414360044
epoch: 0, step: 78, Train: label_loss: 0.6924387812614441, precision: 0.599999999996, recall: 0.4090909090890496, f1: 0.48648648643564646
epoch: 0, step: 79, Train: label_loss: 0.5724912881851196, precision: 0.5333333333297777, recall: 0.399999999998, f1: 0.45714285709126523
epoch: 0, step: 80, Train: label_loss: 0.6033310890197754, precision: 0.49999999999583333, recall: 0.3333333333314815, f1: 0.39999999994933333
epoch: 0, step: 81, Train: label_loss: 0.7868159413337708, precision: 0.46666666666355555, recall: 0.31818181818037194, f1: 0.37837837832812277
epoch: 0, step: 82, Train: label_loss: 0.6187515258789062, precision: 0.4705882352913495, recall: 0.4705882352913495, f1: 0.4705882352413495
epoch: 0, step: 83, Train: label_loss: 0.6942566633224487, precision: 0.19047619047528347, recall: 0.26666666666488886, f1: 0.22222222217237653
epoch: 0, step: 84, Train: label_loss: 0.8247052431106567, precision: 0.4374999999972657, recall: 0.34999999999825004, f1: 0.3888888888373458
epoch: 0, step: 85, Train: label_loss: 0.564861536026001, precision: 0.6153846153798816, recall: 0.5333333333297777, f1: 0.5714285713747449
epoch: 0, step: 86, Train: label_loss: 0.6923263072967529, precision: 0.18749999999882816, recall: 0.17647058823425607, f1: 0.1818181817671258
epoch: 0, step: 87, Train: label_loss: 0.5959782600402832, precision: 0.42857142856836733, recall: 0.5454545454495868, f1: 0.47999999994688
epoch: 0, step: 88, Train: label_loss: 0.6630071401596069, precision: 0.5384615384573964, recall: 0.26923076922973377, f1: 0.35897435892807367
epoch: 0, step: 89, Train: label_loss: 0.5937579870223999, precision: 0.6153846153798816, recall: 0.3333333333319445, f1: 0.4324324323845143
epoch: 0, step: 90, Train: label_loss: 0.5790786743164062, precision: 0.6111111111077161, recall: 0.6874999999957032, f1: 0.6470588234757787
epoch: 0, step: 91, Train: label_loss: 0.5471605062484741, precision: 0.6666666666622222, recall: 0.47619047618820864, f1: 0.555555555503858
epoch: 0, step: 92, Train: label_loss: 0.6243778467178345, precision: 0.6666666666622222, recall: 0.47619047618820864, f1: 0.555555555503858
epoch: 0, step: 93, Train: label_loss: 0.5892693996429443, precision: 0.5714285714258504, recall: 0.5454545454520662, f1: 0.558139534831152
epoch: 0, step: 94, Train: label_loss: 0.6672379970550537, precision: 0.6190476190446712, recall: 0.6842105263121885, f1: 0.6499999999468751
epoch: 0, step: 95, Train: label_loss: 0.5095881223678589, precision: 0.5294117647027682, recall: 0.642857142852551, f1: 0.5806451612370448
epoch: 0, step: 96, Train: label_loss: 0.6699789762496948, precision: 0.5416666666644098, recall: 0.6842105263121885, f1: 0.6046511627385615
epoch: 0, step: 97, Train: label_loss: 0.5673887133598328, precision: 0.5238095238070295, recall: 0.5789473684180056, f1: 0.549999999947375
epoch: 0, step: 98, Train: label_loss: 0.7553483247756958, precision: 0.34999999999825004, recall: 0.4374999999972657, f1: 0.3888888888373458
epoch: 0, step: 99, Train: label_loss: 0.7953236103057861, precision: 0.22222222221975307, recall: 0.12499999999921876, f1: 0.15999999995264003
epoch: 0, step: 100, Train: label_loss: 0.7774778008460999, precision: 0.399999999996, recall: 0.22222222222098767, f1: 0.28571428566632656
